



유저가 자신의 게임을 계속 하게 만들려면 어떻게 해야 할까? 이는 많은 게임 개발자들이 공통으로 고민하는 부분이다. 사람은 같은 게임을 계속 반복하게 되면 지루함을 느끼게 되고, 결국 다른 게임을 찾아가기 때문이다.

유저가 지루함을 느끼지 않게 하기 위해서 개발자들은 발매 전후에 많은 노력을 기울인다. 어떤 게임은 유저가 쉽게 깰 수 없도록 레벨디자인을 하기도 하고, 어떤 게임은 PVP와 멀티플레이에 집중한다. 그러다 일부 개발자들은 인공지능의 개발에 눈을 돌렸다. 게임 속 인공지능도 머신 러닝을 도입해서 유저 못지 않은 실력을 갖도록 하고, 다양한 변수를 플레이 속에 담아내도록 한 것이다.

이번 플레이엑스포 2018 컨퍼런스에서 테레사 드린저 템플게이트 게임즈 CEO는 자신의 게임에 뉴럴 네트워크를 도입, AI에 머신러닝을 구현한 사례를 언급하면서 이 부분에 대한 자신의 노하우를 공유하고자 한다.

드린저 CEO는 보드 게임에 적용한 머신 러닝을 예로 들었다. 사실 보드 게임이야말로 멀티플레이의 기본사례다. 혼자 하는 게임도 있지만, 보통은 여럿이 모여서 서로 경쟁하고, 협력하면서 게임이 진행된다. 이때 인공지능이 플레이어를 대체하도록 하는 것이 드린저 CEO의 목표였다. 보드 게임이 머신 러닝을 적용하기 좋은 이유는 또 있다. 보통의 보드 게임은 여러 턴에 걸쳐서 게임이 진행된다. 그 쪼개진 진행과정 하나하나마다 머신러닝의 재료가 되기 때문이다.




그래서 드린저 CEO가 처음으로 시행한 것도 보드 게임을 디지털화하고, 이를 멀티플레이로 구현하면서 AI를 만들어가는 것이었다. 첫 작품 ‘어센션’부터 드린저 CEO는 본격적으로 AI를 활용했다. 다만 ‘어센션’에 구현한 AI는 지금 적용한 AI와는 다른 방식을 사용했다.

전통적으로 게임의 인공지능을 구현할 때는 알고리즘 방식을 사용한다. 시나리오를 작성하고, 그 시나리오마다 분기점을 만들고 그 분기점마다 다른 항목으로 가도록 하는 방식이다. 예를 들자면 덱을 짰을 떄, 가성비가 좋은 카드로 구성되어있느냐? 라고 묻고 그에 따른 답에 따라 행동 양식을 다르게 하도록 하는 것이다.



사실 이런 시나리오 구성 자체는 덱 빌딩을 알건 모르건 관계가 없다. 기본적으로 시나리오가 구성되어있으며, 해당 경우에 따라서 어떤 선택지를 고르도록 설계가 되어있다. 이때 필요한 것은 다양한 시나리오를 최대한 생각하고, 그 경우를 하나하나 맞춰서 인공지능에게 주는 것이다. 이런 방식이 예전 게임에서 주로 사용하던 인공지능 구현 방식이라고 드린저 CEO는 설명했다.

이 방식은 개발자들에게 익숙한 방식이고, 전통적인 방식인 만큼 구성하기도 쉽다. 그렇지만 여러 문제가 발생한다. AI에게 모든 경우의 수를 다 하나하나 설명하는 방식이기 때문이다. 즉 돌발 변수가 발생하면, 그 돌발 변수에 대해서 하나하나 입력하고 시나리오를 수정해나가야 한다.

또한 전통적인 방식으로는 모호한 개념에 대해서 다양하게 대응하는 방법을 구현하는 것도 어렵다. 예를 들어서 ‘최적의 카드를 갖고 있도록 하라’고 AI에게 입력한다고 생각하면, 개발자들이 직접 ‘최적의 카드’의 조건에 대해서 정의하고 이를 코드로 짜서 넣어야 한다.

하지만 최적의 카드라는 말은 굉장히 모호한 개념이다. 어떤 것이 최적의 카드인가? 그것은 게임의 특성마다 다 다르고, 상황마다 다 다르다. 또 게임을 많이 해본 사람의 경우, 종종 전통적인 최적의 수 말고 다른 묘수로 상대방을 이기기도 한다. 이것을 하나하나 다 고려하고, 코드를 짜고자 하면 시간과 노력이 많이 들고, 때로는 오류가 생길 수 있다고 드린저 CEO는 역설했다.


드린저 CEO가 이런 방식에서 탈피하기 위해서 도입한 방식이 뉴럴 네트워크 방식이다. 또 다른 게임 ‘레이스 포 더 갤럭시’에는 13년에 오픈소스로 올라온 뉴럴 네트워크툴을 활용했고, 게임 외적으로 광고 및 자동 수정 등에도 뉴럴 네트워크 방식을 일부 도입했다. 아울러 해당 뉴럴 네트워크 소스를 개발한 캘튼 존스와 함께 작업하면서 뉴럴 네트워크를 좀 더 보완해나갔다.

이들은 일단 뉴럴 네트워크을 좀 더 효과적으로 사용하기 위해서 슬로팅이라는 고전 게임으로 테스트를 진행했다. 우선 뉴럴 네트워크 방식을 통해서 최선의 수 이상이라는 것을 만들 수 있는지, 확인해본 것이다. 천 판에 가까운 시뮬레이션 끝에 기존의 수와는 다른 수를 산출해냈고, 그 수가 승률이 높다는 것을 산출해냈다. 이에 이들은 뉴럴 네트워크를 게임에 적극적으로 도입하기로 했고, 최적의 수를 산출할 수 있던 이유에 대해서 되짚어갔다.

인공지능은 어떻게 해서 최적의 수를 산출할 수 있을까? 드린저 CEO는 가장 먼저 ‘편견이 없기 때문’이라고 답을 도출해냈다고 밝혔다. 사람은 무의식적으로 편견을 갖고 접근을 한다. 바둑이나 체스도 정석으로 여겨지는 수들을 최우선적으로 고려하는 경향이 있다. 그렇지만 인공지능의 선택 기준은 간단하다. 승률이 높은가, 낮은가, 이것이 전부다. 승률이 높다면 얼마든지 사람들이 보기에 기괴한 수라고 해도 바로 시행해버리고, 승률이 낮으면 정석이라고 알려진 수라고 해도 두지 않는다. 이런 경우는 이미 다양한 사례를 통해서 소개가 됐지만, 의외로 개발자들이 놓치기 쉬운 부분이라고 덧붙였다.

드린저 CEO는 비용절감 측면에서 뉴럴 네트워크가 고려할 만한 솔루션이라고 언급했다. 기존 방식은 앞서 말했듯 데이터와 변수를 최대한 많이 확보하고 이를 지속적으로 주입해야 하는 방식이다. 예를 들어 인공지능에게 ‘고양이’가 어떤 존재인지 각인시키려면 각각 다른 고양이 사진을 몇 천 장을 입력하는 것이다. 각기 다른 고양이를 보고도 고양이라는 동일한 카테고리로 집어넣게 하기 위해서는 그만큼 사전에 코스트가 많이 든다.



이와 달리 뉴럴 네트워크에는 TD 러닝이 도입되어있다. TD 러닝은 순수한 경험만으로 직접 학습할 수 있다는 것을 이론의 기점으로 두고 있는 개념이다. 즉 사전에 어떤 정보를 입력하지 않아도 에이아이를 구축할 수 있다는 장점이 있다.

그렇다면 사전 정보를 입력하지 않고 데이터를 어떻게 축적하고 학습해나갈 수 있을까? 뉴럴 네트워크 방식은 뉴런과 같다고 드린저 CEO는 힌트를 제공했다. 뉴런은 자극에 반응하고, 이 반응을 자극물질을 통해 다른 뉴런에게 전달하는 연쇄작용을 거친다. 이처럼 인풋을 주고, 아웃풋을 도출해내고 아웃풋의 반응을 통해서 또 인풋이 일어나는 연쇄적인 러닝이 일어나는 것이다.

이 경우에 사전 지식은 크게 도움이 되지 않으며, 오히려 인공지능에 제약을 줄 수 있다고 드린저 CEO는 경고했다. 사전 지식은 제한된 경우의 수인데, 이런 제한된 인풋을 주게 되면 아웃풋 역시도 일정하게 나오기 때문에 다양한 변수에 대한 고려를 하지 않게 되기 때문이다.



도출되는 아웃풋은 복잡할 필요가 없다. 레이스 포 더 갤럭시에 적용된 AI 모델의 경우에는 승리, 패배로 도입했다. 게임에 승리했을 때 승리한 수를 우선 순위에 두고, 패배한 경우에는 그 패배한 수를 다시금 되짚어가면서 승리할 때까지 하나하나 다르게 적용해보도록 하는 것이다.

카드 게임을 예로 든다면 덱에 카드가 몇 장 있는가, 어떤 카드가 있는가에 따라서 변수가 일일이 나뉘게 된다. 그렇지만 뉴럴 네트워크와 TD 러닝 방식을 활용하면 이를 처음부터 고려할 필요가 없다. 왜냐하면 그 부분은 AI가 플레이를 반복적으로 진행하면서 자신이 산출할 부분이기 때문이다. 4인용 덱 게임을 예로 든 드린저 CEO는 처음 확률은 공평하게 25퍼센트로 두었다. 다수의 4인용 덱 게임은 턴이 진행됨에 따라서 승과 패, 그리고 중간 점수가 산출되게 되는데, 승리한 경우에는 전턴의 승률을 70퍼센트의 승률로 두고 나머지 2명은 승률을 각각 15퍼센트, 패한 경우를 0으로 아웃풋을 계산하도록 했다. AI는 이를 토대로 TD 러닝의 공식을 대입해 트래킹을 거치고, 러닝을 진행하게 되는 것이다.

일반적으로 TD 러닝의 공식을 보면, 수열의 공식을 적용한다. 수열은 항이 한두 개일 때는 큰 의미를 갖지 않는다. 항이 여럿, 수가 다양해질 때 그 의미가 배가 된다. 드린저 CEO도 TD 러닝과 뉴럴 네트워크를 적용한 AI도 마찬가지라고 지적했다. 처음에는 의미 있는 수치나, 의미 있는 움직임을 보여주지 않는다. 그러다가 항이 많아지고, 경험이 축적되면서 AI가 비로소 의도한 만큼, 혹은 그 이상의 모습을 보여준다는 것이다.

![사진](http://static.inven.co.kr/column/2018/05/10/news/i13636589534.jpg)
<br>
![사진](http://static.inven.co.kr/column/2018/05/10/news/i15902259802.jpg)

▲ 최종적으로 이런 공식을 도입했다. 알파값은 임의 변수다

드린저 CEO의 경험으로 볼 때, 에이아이가 처음에 플레이했을 때는 가장 단순한 규칙을 파악하고 그것만 의존해서 게임을 진행한다. 코스트값만 신경 써서 그 코스트에 딱 맞는 카드만 쓰거나, 혹은 고코스트 카드를 센 카드로 인식해서 그것만 낸다거나 하는 방식이다. 그 방식으로 계속 반복하다가 AI는 시뮬레이션 내에서 패배하는 경우를 대면하게 되고, 그렇게 되면 다른 방식을 적용하게 된다. 흔히 이야기하는 가성비나, 혹은 특수 효과로 인한 변수를 하나하나 차례차례 적용하게 되는 것이다.

AI는 각 경우의 수를 하나하나 적용해나가기 때문에 처음 인공지능은 굉장히 이상한 수를 던진다. 그렇지만 그 수를 트래킹하면서 결국에는 다른 방식들을 파악하고, 더 나은 수를 내게 된다. 앞서 말했듯 하나하나 순차적으로 대입하고, 시뮬레이션하기 때문에 각 모드별로 더 나은 수를 AI가 고려하게 하기 위해서는 모드별로 다른 뉴럴 네트워크를 갖추는 것도 좋은 방법이라고 드린저 CEO는 조언한다.

실제로 레이스 포 더 갤럭시에 적용한 뉴럴 네트워크는 12개다. 2인, 3인 모드나 인공지능 대전 등 각각의 상황에 맞춰서 네트워크와 러닝을 구축했기 때문이다. 하지만 여기에 한 가지 더 추가할 것이 있다. 승리하기 위해서는 상대방의 수를 예측할 필요가 있다. 따라서 상대방의 수라는 변수를 계산하기 위한 또 다른 뉴럴 네트워크 브랜치가 필요하다. 그들 간의 시뮬레이션을 통해서 상대의 수를 예측한 수를 내는 것이 가능해지기 때문이다. 그래서 드린저 CEO가 최종 도입한 뉴럴 네트워크는 브랜치를 포함해서 24개가 되었다.



다만 이렇게 구축한 AI를 레이스 포 더 갤럭시 라이브 서비스에 직접 집어넣지는 않았다고 밝혔다. 왜냐하면 AI가 지속적으로 발전하게 되면 난이도가 기하급수적으로 상승하는데, 그렇게 되면 초보 유저들은 곧 흥미를 잃고 게임을 접어버리기 때문이다. 따라서 난이도를 어느 정도 조절하기 위해서 라이브 서비스에는 활성화시키지 않고, 개발 간에만 활성화시켰다고 밝혔다.

그렇다고 해서 AI를 처음부터 적당히, 혹은 좀 더 쉽게 만드는 것은 좋지 않다고 강조했다. 왜냐하면 수준이 낮은 AI를 끌어올리는 것보다, 수준이 높은 AI를 끌어내리는 것이 더 쉽기 때문이다. AI의 질이나 실력을 끌어올리기 위해서는 반복경험의 횟수를 늘리는 것 외에도 다른 변수를 고려해야 한다. 하지만 AI의 질을 낮추기 위한 방법은 간단하다. 노이즈 데이터를 약간만 부여해줘도 AI는 혼동을 일으키기 때문이다. 랜덤 요소 부여는 이런 점에서 많이 사용되는 방법 중 하나다.

드린저 CEO는 뉴럴 네트워크와 TD 러닝을 활용한 AI가 모든 콘텐츠에 적합한 형태는 아니라고 지적했다. 그의 경험으로 볼 때 적합한 형태는 다양한 인풋이 주어지고, 일정한 룰이 있으며, 끝이 명확한 형태의 게임이다. 드린저 CEO는 체스의 예를 통해서 부적합한 형태에 대해서 설명했다. 체스는 인풋이 적다. 말이 움직이는 방식도 제한되어있으며, 체스판의 크기도 크지 않다. 때로는 10수 안으로 끝나기도한다. 일정한 룰이 있긴 하지만, 끝이 명확하진 않다. 앞서 말한 것처럼 빨리 끝나기도 하지만, 때로는 체크를 계속 반복하면서 질질 끌어가는 형태로 진행되기도 한다.

그래서 레이스 포 더 갤럭시를 기획할 때는 이 점에 유의해서 설계를 했다. 카드의 종류를 늘리고, 효과와 코스트 분배 등을 다양화해서 인풋을 늘렸다. 또한 카드와 효과에 대한 룰을 확고히 했으며, 30턴 내에 승부가 끝나지 않을 때 게임이 끝나도록 설정해서 ‘끝’이라는 것을 도입했다. 여기서 드린저 CEO는 끝을 설정하는 것이 상당히 중요한 요소라고 강조했다. AI는 한 게임이 끝나고 결과가 나오고 나서야 그 과정을 트래킹한다. 반대로 이야기하면 결과가 나오지 않으면 트래킹을 하지 않는다는 말이다. 즉 기본적인 TD 러닝의 과정이 이루어지지 않기 때문에, 게임이 끝났음을 AI에게 인식시키는 것이 중요하다.


▲ 트래킹 등의 작업은 한 판이 끝났을 때 시작하기 때문에, 그 끝을 명확히 명시해주는 것이 좋다

머신 러닝으로 게임에 적용할 AI를 만들고자 할 때, 드린저 CEO는 실제 유저와의 대전이 인공지능의 질을 향상시킬 수 있는 가장 좋은 방법이라고 설명했다. 인공지능이 혼자서 하나하나 따져가면서 인풋과 아웃풋을 계속 산출하고, 이를 통해서 배우는 과정도 가능하다. 그러나 많은 유저들과 계속 대전을 하게 되면 이 과정에 소요되는 시간을 줄일 수 있다. 레이스 포 더 갤럭시 개발 동안에 드린저 CEO는 개발 빌드를 일부 커뮤니티에 올렸고, 유저 피드백을 통해서 더 인공지능을 빨리 향상시킬 수 있었다고 회고했다.


▲ 머신 러닝 과정을 단축하려면 실제 유저와 대전하도록 하는 것이 좋다

현재 드린저 CEO는 머신 러닝을 활용해서 또 다른 보드 게임 ‘롤 포 더 갤럭시’를 모바일로 만들고자 하고 있다. ‘롤 포 더 갤럭시’는 레이스 포 더 갤럭시를 기반으로 했지만, 다른 룰이 적용된다. 특히나 이전보다 랜덤 요소가 더 삽입된 것이 특징이다. 다만 랜덤 요소가 늘어난 만큼, 최초 변수를 설정할 때 이전보다 더 복잡한 과정을 거쳐야 했다고 드린저 CEO는 고백했다. 실제로 랜덤 요소라는 것을 인공지능에 맞춰서 구축하는 과정은 어렵다. 어떻게 정의하기 모호하기 때문이다. 모호한 것을 인공지능이 어느 정도, 머신 러닝을 통해서 인지할 수 있다. 그러나 최초에 인공지능이 러닝을 하기 위해서는 변수의 폭을 정해줘야 하는데, 이를 어떻게 정하느냐에 따라 완전히 다른 방향으로 갈 수 있다. 따라서 이 부분은 시행착오를 통해서 계속 수정해나갈 필요가 있다.

이와 같은 문제들 때문에 처음에 개발자들은 뉴럴 네트워크, TD 러닝 방식이 게임에 회의적이었다고 드린저 CEO는 회고했다. 게임에는 다양한 랜덤 요소가 있는데, 그에 맞는 변수를 적용해서 적합한 뉴럴 네트워크나, TD 러닝 방식을 구현하기가 어려웠기 때문이다. 그렇지만 랜덤이 섞이면서도 어느 정도 예측이 가능하고, 일정한 룰에 따라서 움직이는 보드 게임이나 전략 게임이 강세를 보이면서 뉴럴 네트워크나 TD 러닝 방식을 게임에서 활용할 수 있게 됐다고 덧붙였다. 드린저 CEO는 이후에 머신 러닝에 대한 연구가 더 진행되면, 더 많은 랜덤 요소도 인공지능이 고려해서 수를 짜낼 수 있고, 더 다양한 게임에 활용할 수 있을 것이라고 하면서 앞으로의 기술에 더 관심을 기울일 필요가 있다고 강조했다.

